experiment:
  generate_experiment_dir: /mnt/data/experiments/nils/testing
  # generate_experiment_dir: /mnt/data/experiments/pau/partition_sweeps_classification
  experiment_name: 0.01x_train # prefix
  experiment_type: sweep # standard, seeded_runs, sweep
  benchmark_dir: /mnt/data/cc_benchmark/classification_v0.8.1
  partition_name: 0.01x_train
  tasks: ["so2sat", "brick_kiln_v1.0", "eurosat", "bigearthnet"] #, "pv4ger_classification", "forestnet_v1.0"]
wandb:
  project: geobench # wandb project name
  entity: climate-benchmark # user or team entity that hosts a project
  sweep:
    sweep_config_path: /mnt/home/geo-bench-experiments/geobench/torch_toolbox/wandb/hparams_classification_resnet50.yaml # or maybe define the entire sweep here?
    num_agents: 1 # how many agents participate in sweep, one agent usually corresponds to one gpu
    num_trials_per_agent: 1 # how many hparam trials each agent should execute, num_agents x num_trials_per_agent corresponds to total number of trials executed by sweep
model:
  model_generator_module_name: geobench.torch_toolbox.model_generators.timm_generator
  loss_type: crossentropy
  # ssl_method: dino
  backbone: resnet50 # resnet18, convnext_base, vit_tiny_patch16_224, vit_small_patch16_224. swinv2_tiny_window16_256
  desired_input_size: 224
  pretrained: True
  # weights: ResNet50_Weights.SENTINEL2_RGB_MOCO
  lr_backbone: 1.0e-6
  lr_head: 1.0e-4
  optimizer: sgd
dataset:
  band_names: "all" #["red", "green", "blue"]
  format: hdf5
dataloader:
  num_workers: 4
pl: # all flags for pytorch lightning Trainer module, see https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html
  gpus: 1
  accelerator: gpu
  max_epochs: 600
  max_steps: -1
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  val_check_interval: 0.25
  deterministic: False
  log_every_n_steps: 10
  enable_progress_bar: False